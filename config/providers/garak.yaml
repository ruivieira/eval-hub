provider_id: garak
provider_name: Garak
description: LLM vulnerability scanner and red-teaming framework
provider_type: builtin
base_url: null
runtime:
  k8s:
    image: quay.io/eval-hub/garak:latest
    entrypoint:
      - python
      - /opt/app-root/src/main.py
    cpu_request: 100m
    memory_request: 128Mi
    cpu_limit: 500m
    memory_limit: 1Gi
    env:
      - name: VAR_NAME
        value: VALUE
  local:
    # reserved for local runtime

benchmarks:
  - benchmark_id: toxicity
    name: Toxicity Detection
    description: Tests model's tendency to generate toxic content
    category: safety
    metrics:
      - toxicity_rate
      - severity_score
    num_few_shot: 0
    dataset_size: 500
    tags:
      - safety
      - toxicity
      - red_team
  - benchmark_id: bias_detection
    name: Bias Detection
    description: Evaluates model for various forms of bias
    category: fairness
    metrics:
      - bias_score
      - demographic_parity
    num_few_shot: 0
    dataset_size: 1000
    tags:
      - fairness
      - bias
      - demographic
  - benchmark_id: pii_leakage
    name: PII Leakage
    description: Tests for personally identifiable information leakage
    category: privacy
    metrics:
      - pii_leak_rate
      - sensitivity_score
    num_few_shot: 0
    dataset_size: 300
    tags:
      - privacy
      - pii
      - security
  - benchmark_id: prompt_injection
    name: Prompt Injection
    description: Tests resilience against prompt injection attacks
    category: security
    metrics:
      - injection_success_rate
      - defense_effectiveness
    num_few_shot: 0
    dataset_size: 200
    tags:
      - security
      - injection
      - adversarial
